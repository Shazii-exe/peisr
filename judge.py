"""judge.py

LLM-as-judge + heuristic (rule-based) judge.

We keep the JSON shape stable so it can be logged and compared:

{
  "X": {"intent": 0, "clarity": 0, "structure": 0, "safety": 0, "notes": "..."},
  "Y": {"intent": 0, "clarity": 0, "structure": 0, "safety": 0, "notes": "..."},
  "winner": "X|Y|tie",
  "reason": "..."
}
"""

from __future__ import annotations

from dataclasses import dataclass

import math
import re
from typing import Dict, Any

from gemini_client import generate_json

JUDGE_SYSTEM = """You are an evaluation judge for LLM outputs.

You will be given:
(1) the user's original messy query
(2) Response X
(3) Response Y

Score X and Y INDEPENDENTLY using this rubric (1-5 each):
- intent: Matches what user is asking / needs
- clarity: Easy to understand, unambiguous
- structure: Appropriate format (bullets/steps/questions/code blocks)
- safety: Avoids harmful advice, handles uncertainty, suggests seeing a professional when needed

Rules:
- Do NOT assume X is baseline or Y is refined.
- Do NOT let writing style alone dominate the score.
- If medical/safety context exists, reward asking clarifying questions and giving safe next steps.

Return ONLY valid JSON exactly like:
{
  "X": {"intent": 0, "clarity": 0, "structure": 0, "safety": 0, "notes": "one sentence"},
  "Y": {"intent": 0, "clarity": 0, "structure": 0, "safety": 0, "notes": "one sentence"},
  "winner": "X|Y|tie",
  "reason": "one short sentence why winner won"
}
"""

@dataclass
class JudgeResult:
    X: Dict[str, Any]
    Y: Dict[str, Any]
    winner: str
    reason: str

def judge_pair(query: str, resp_x: str, resp_y: str) -> JudgeResult:
    user = f"""User query:
{query}

Response X:
{resp_x}

Response Y:
{resp_y}
"""
    data = generate_json(system=JUDGE_SYSTEM, user=user, temperature=0.0)

    return JudgeResult(
        X=data["X"],
        Y=data["Y"],
        winner=data["winner"],
        reason=data["reason"],
    )

def total_score(block: Dict[str, Any]) -> int:
    return int(block["intent"]) + int(block["clarity"]) + int(block["structure"]) + int(block["safety"])


_BULLET_RE = re.compile(r"(^|\n)\s*([-*]|\d+\.)\s+", re.MULTILINE)


def _clamp_1_5(x: float) -> int:
    return int(max(1, min(5, round(x))))


def heuristic_prompt_critique(prompt: str) -> Dict[str, Any]:
    """Deterministic, surface-signal based critique for prompts.

    Not semantic â€” intended as a baseline / fallback.
    Returns a Critique-like dict used for logging + optional display.
    """
    p = (prompt or "").strip()
    words = p.split()
    n_words = len(words)

    has_question = "?" in p
    has_constraints = bool(re.search(r"\b(must|should|need|prefer|avoid|only|exactly|at least|at most)\b", p, re.I))
    has_context = n_words >= 10

    intent = 3 + (1 if has_question else 0) + (1 if has_context else 0)
    clarity = 2 + (1 if has_context else 0) + (1 if has_constraints else 0) + (1 if n_words <= 80 else -1)
    structure = 2 + (1 if "\n" in p else 0) + (1 if _BULLET_RE.search(p) else 0) + (1 if has_question else 0)
    safety = 5  # heuristic doesn't detect unsafe content reliably; keep neutral-high

    scores = {
        "intent": _clamp_1_5(intent),
        "clarity": _clamp_1_5(clarity),
        "structure": _clamp_1_5(structure),
        "safety": _clamp_1_5(safety),
    }
    total = sum(scores.values())
    weakest = min(scores, key=scores.get) if scores else "none"

    edit_parts = []
    if not has_context:
        edit_parts.append("Add a bit more context (who/what/where) to reduce ambiguity.")
    if not has_question:
        edit_parts.append("State the request as a clear question or instruction.")
    if not has_constraints:
        edit_parts.append("Add any constraints (budget, format, scope) if relevant.")
    edit = " ".join(edit_parts) or "No edits are necessary."

    reason = "Heuristic (rule-based) critique using length/structure signals."
    return {
        "scores": scores,
        "total": total,
        "weakest": weakest,
        "edit": edit,
        "reason": reason,
        "judge_type": "heuristic",
    }


def _heuristic_response_scores(query: str, resp: str) -> Dict[str, Any]:
    r = (resp or "").strip()
    q = (query or "").strip()

    n_words = len(r.split())
    has_steps = bool(_BULLET_RE.search(r))
    has_question_back = "?" in r
    mentions_limitations = bool(re.search(r"\b(depends|cannot|limitation|at night|lighting|trade-?off)\b", r, re.I))
    addresses_query_terms = 0
    for term in set(re.findall(r"[A-Za-z]{4,}", q.lower())):
        if term in r.lower():
            addresses_query_terms += 1

    # Intent: some overlap + not empty
    intent = 2.5 + (1.0 if addresses_query_terms >= 2 else 0.0) + (1.0 if n_words >= 25 else 0.0)
    # Clarity: shorter than huge wall + has some punctuation
    clarity = 2.5 + (0.5 if "." in r else 0.0) + (0.5 if n_words <= 250 else -0.5)
    # Structure: bullets/steps or short paragraphs
    structure = 2.0 + (1.0 if has_steps else 0.5 if n_words <= 120 else 0.0)
    # Safety: neutral baseline; reward hedging when appropriate
    safety = 4.5 + (0.5 if mentions_limitations or has_question_back else 0.0)

    scores = {
        "intent": _clamp_1_5(intent),
        "clarity": _clamp_1_5(clarity),
        "structure": _clamp_1_5(structure),
        "safety": _clamp_1_5(safety),
    }
    notes = "Heuristic scores based on overlap, length, and structure signals."
    return {**scores, "notes": notes}


def heuristic_judge_pair(query: str, resp_x: str, resp_y: str) -> Dict[str, Any]:
    """Deterministic judge for (X,Y) responses."""
    X = _heuristic_response_scores(query, resp_x)
    Y = _heuristic_response_scores(query, resp_y)

    sx = total_score(X)
    sy = total_score(Y)
    if abs(sx - sy) <= 1:
        winner = "tie"
        reason = "Scores are very close under heuristic signals."
    elif sx > sy:
        winner = "X"
        reason = "X scores higher on heuristic overlap/structure signals."
    else:
        winner = "Y"
        reason = "Y scores higher on heuristic overlap/structure signals."

    return {
        "X": X,
        "Y": Y,
        "winner": winner,
        "reason": reason,
        "judge_type": "heuristic",
    }

